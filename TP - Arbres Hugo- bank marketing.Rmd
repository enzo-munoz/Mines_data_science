---
title: "TP - Abres de décision et forêts aléatoires"
author: "Enzo Munoz - Hugo Munier - Maxime Guilbaud"
date: "2025-10-21"
output:
  pdf_document:
    latex_engine: xelatex
  html_document:
    html_document:
    toc: true
    toc_float: true
    theme: cosmo
header-includes:
  - \usepackage{float}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(
  fig.width = 7,        
  fig.height = 4.5,
  out.width = "90%",    
  fig.align = "center", 
  fig.pos = "H"       
)
knitr::opts_chunk$set(
  message = FALSE,   
  warning = FALSE    
)
```

```{r}
# Bibliothèques utilisées

#install.packages("ggcorrplot")
#install.packages("GGally")
#install.packages("corrplot")
library(GGally)
library(ggplot2)
library(ggcorrplot)
library(corrplot)
```

```{r}
# Importation des données

data <- read.csv("C:/Users/hugom/OneDrive - Aescra Emlyon Business School/Mines de Saint-Etienne/3A/Science des données/Arbres de décision et forêts aléatoires/TP/7 bank_marketing.csv", 
                 sep=";", header=TRUE)
head(data)
summary(data)
```

```{r}
# valeurs manquantes
print("=== Nombre de NA par variable ===")
colSums(is.na(data))
print("=== Nombre de 'unknown' par variable ===")
sapply(data, function(x) sum(x == "unknown", na.rm=TRUE))
```

```{r}
# Transformation en facteur
factor_vars <- c("marital", "education", "contact", "poutcome", "default", "housing", "loan", "class")
data[factor_vars] <- lapply(data[factor_vars], as.factor)

# Transformation en numérique
numeric_vars <- c("balance", "age")
data[numeric_vars] <- lapply(data[numeric_vars], as.numeric)

# Vérification
str(data)
summary(data)
```
```{r}
# Analyse univariée
hist(data$age,
     main = "Distribution de l'âge",
     xlab = "Âge",
     col = "skyblue",
     border = "white",
     breaks = 20)

hist(data$balance,
     main = "Distribution du solde (balance)",
     xlab = "Balance (€)",
     col = "orange",
     border = "white",
     breaks = 50,
     xlim = c(-5000, 10000))

boxplot(data$age,
        main = "Boxplot de l'âge",
        col = "skyblue",
        horizontal = TRUE)

boxplot(data$balance,
        main = "Boxplot du solde (balance)",
        col = "orange",
        horizontal = TRUE)


for (var in factor_vars) {
  print(
    ggplot(data, aes_string(x = var, fill = var)) +
      geom_bar() +
      labs(title = paste("Répartition de", var),
           x = var,
           y = "Effectifs") +
      theme_minimal() +
      theme(legend.position = "none")
  )
}
```

```{r}
# Analyse bivariée

ggplot(data, aes(x = class, y = age, fill = class)) +
  geom_boxplot() +
  labs(title = "Boxplot de l'âge par classe",
       x = "Classe (Souscription dépôt à terme)",
       y = "Âge") +
  theme_minimal()

ggplot(data, aes(x = age, fill = class)) +
  geom_density(alpha = 0.5) +
  labs(title = "Densité de l'âge selon la classe",
       x = "Âge", y = "Densité") +
  theme_minimal()

ggplot(data, aes(x = class, y = balance, fill = class)) +
  geom_boxplot() +
  labs(title = "Boxplot du solde (balance) par classe",
       x = "Classe (Souscription dépôt à terme)",
       y = "Solde du compte (€)") +
  theme_minimal()

boxplot(balance ~ class, 
        data = data,
        main = "Distribution du solde par classe (zoom)",
        xlab = "Classe (Souscription dépôt à terme)",
        ylab = "Solde (€)",
        col = c("orange", "skyblue"),
        ylim = c(-2000, 10000))

table(data$marital, data$class)
prop.table(table(data$marital, data$class), margin = 1)

# Barplot empilé

ggplot(data, aes(x = marital, fill = class)) +
  geom_bar(position = "fill") +
  labs(title = "Taux de souscription selon marital",
       x = "Situation maritale", y = "Proportion") +
  scale_y_continuous(labels = scales::percent) +
  theme_minimal()

table(data$education, data$class)
prop.table(table(data$education, data$class), margin = 1)

ggplot(data, aes(x = education, fill = class)) +
  geom_bar(position = "fill") +
  labs(title = "Taux de souscription selon éducation",
       x = "Niveau d'éducation", y = "Proportion") +
  scale_y_continuous(labels = scales::percent) +
  theme_minimal()

for (var in c("housing", "loan", "default")) {
  print(table(data[[var]], data$class))
  print(prop.table(table(data[[var]], data$class), margin = 1))
  
  print(
    ggplot(data, aes_string(x = var, fill = "class")) +
      geom_bar(position = "fill") +
      labs(title = paste("Taux de souscription selon", var),
           x = var, y = "Proportion") +
      scale_y_continuous(labels = scales::percent) +
      theme_minimal()
  )
}

table(data$contact, data$class)
prop.table(table(data$contact, data$class), margin = 1)

ggplot(data, aes(x = contact, fill = class)) +
  geom_bar(position = "fill") +
  labs(title = "Taux de souscription selon type de contact",
       x = "Type de contact", y = "Proportion") +
  scale_y_continuous(labels = scales::percent) +
  theme_minimal()

table(data$poutcome, data$class)
prop.table(table(data$poutcome, data$class), margin = 1)

ggplot(data, aes(x = poutcome, fill = class)) +
  geom_bar(position = "fill") +
  labs(title = "Taux de souscription selon résultat campagne précédente",
       x = "Résultat précédent", y = "Proportion") +
  scale_y_continuous(labels = scales::percent) +
  theme_minimal()
```

```{r}
numeric_data <- data[, numeric_vars]

cat_vars <- c("marital", "education", "default", "housing", "loan", "contact", "poutcome","class")
dummies <- dummyVars(~ ., data = data[, cat_vars])
cat_data <- data.frame(predict(dummies, newdata = data))

data_corr <- cbind(numeric_data, cat_data)
cor_matrix <- cor(data_corr, use = "complete.obs")

plot_df <- cbind(data_corr, class = data$class)

vars_to_plot <- c("age", "balance", "marital.married", "marital.divorced","marital.single", "education.tertiary", "housing.yes", "loan.yes", "poutcome.success")

corrplot(cor_matrix, method = "color", type = "upper",
         tl.cex = 0.7,
         title = "Matrice de corrélations")

```
## PARTIE II - Foret aléatoire


```{r}
library(tidyverse)
library(data.table)
library(janitor)
library(skimr)
library(caret)
library(pROC)
library(randomForest)
library(ranger)
library(rpart)
library(rpart.plot)
```
## Split Apprentissage
```{r}
target_col <- "class"
levels(data[[target_col]])

x_cols <- setdiff(names(data), target_col)

set.seed(1234)
idx <- createDataPartition(data[[target_col]], p = 0.8, list = FALSE)
train <- data[idx, ]
test  <- data[-idx, ]

dim(train)
dim(test)

prop.table(table(train[[target_col]]))
prop.table(table(test[[target_col]]))
```
Dans cette première partie "Split apprentissage", nous avons séparé l’échantillon en deux jeux de données : 80 % pour l’apprentissage et 20 % pour le test. Après cette séparation, on retrouve dans chaque jeu environ 77 % de "no" et 23 % de "yes". Cela montre que le jeu de test reste représentatif de l’ensemble des données et pourra donc servir à évaluer correctement la capacité de généralisation des modèles. Ce point est important, car la classe "yes" étant minoritaire, il faut s’assurer que cette proportion soit bien conservée dans le jeu de test afin d’éviter un biais et d’obtenir des indicateurs de performance fiables.

## Schéma de validation et métriques

```{r}
ctrl <- trainControl(
  method = "repeatedcv",
  number = 5, repeats = 2,
  classProbs = TRUE,
  summaryFunction = twoClassSummary,
  sampling = "down",
  savePredictions = "final"
)
```
Nous avons ensuite mis en place un schéma de validation pour évaluer et comparer les deux modèles de forêts aléatoires. Le jeu d’apprentissage est soumis à une validation croisée à 5 folds, répétée deux fois afin de limiter la variance des estimations. Comme la variable "class" est déséquilibrée, nous appliquons un down sampling à chaque fold afin d’éviter que le modèle n’apprenne à prédire uniquement "no". Les performances sont alors mesurées à l’aide de plusieurs indicateurs : l’AUC/ROC, la sensibilité et la spécificité. Enfin, une évaluation finale est réalisée sur le jeu de test pour estimer la capacité de généralisation de nos deux modèles.

## Arbre de décision illustratif
```{r}
model_tree <- rpart(class ~ ., data = train, method = "class")
rpart.plot(model_tree, type=2, extra=104, main="Arbre de décision")
```
Avant de passer à la modélisation avec les deux forêts aléatoires, nous avons ajouté un arbre de décision à titre de rappel. Celui-ci met en évidence que la variable "poutcome" joue un rôle central dans la prédiction : lorsque poutcome vaut "failure" ou "other", la probabilité de non-souscription atteint 86 %, tandis qu’en cas de "success", 65 % des clients souscrivent à nouveau. Cet arbre illustre bien la logique de segmentation, mais il reste limité puisqu’il ne repose que sur une règle principale et demeure instable. Pour obtenir un modèle plus robuste et généralisable, il est donc nécessaire d’utiliser une forêt aléatoire, issue de la combinaison de nombreux arbres.

## Implémentation A
```{r}
grid_rf <- expand.grid(
  mtry = floor(seq(2, sqrt(length(x_cols))*2, length.out = 6))
)

set.seed(1234)
rf_fit <- train(
  x = train[, x_cols],
  y = train[[target_col]],
  method = "rf",
  metric = "ROC",
  trControl = ctrl,
  tuneGrid = grid_rf,
  ntree = 500,
  importance = TRUE
)

print(rf_fit)

plot(rf_fit, main = "Performance ROC en fonction de mtry (Random Forest)")
```
Notre premier modèle repose sur l’implémentation classique du Random Forest. Nous avons testé différentes valeurs de l’hyperparamètre mtry, qui correspond au nombre de variables candidates sélectionnées aléatoirement à chaque division de nœud. L’évaluation a été réalisée selon le schéma de validation décrit précédemment. Les résultats montrent que la performance, mesurée par l’AUC (ROC), diminue lorsque mtry augmente. Le maximum est atteint pour mtry = 2 avec une AUC de 0,796, puis elle baisse progressivement jusqu’à 0,761 pour mtry = 6. En effet un nombre trop important de variables à chaque split réduit la diversité des arbres et favorise le sur-apprentissage, d'pù cette évolution de l'AUC. Le modèle optimal retenu est donc celui avec mtry = 2. Il offre également le meilleur compromis entre sensibilité (0,761) et spécificité (0,721). Ce réglage maximise la capacité discriminante de la forêt aléatoire et améliore la détection des souscripteurs, objectif principal de notre étude.

## Imlplémentation B
```{r}
grid_rg <- expand.grid(
  mtry = floor(seq(2, sqrt(length(x_cols))*2, length.out = 6)),
  splitrule = c("gini", "extratrees"),
  min.node.size = c(1, 5, 10)     
)

set.seed(1234)
rg_fit <- train(
  x = train[, x_cols],
  y = train[[target_col]],
  method = "ranger",
  metric = "ROC",
  trControl = ctrl,
  tuneGrid = grid_rg,
  num.trees = 500,
  importance = "permutation",
  respect.unordered.factors = "partition"
)

print(rg_fit)

plot(rg_fit, main = "Performance ROC selon hyperparamètres (Ranger)")
```
Notre second modèle repose sur l’implémentation Ranger, choisie car elle permet un réglage plus fin des hyperparamètres, même si son coût de calcul est plus élevé que celui du Random Forest. Elle offre notamment la possibilité de contrôler la structure des arbres via différents paramètres : min.node.size (taille minimale des nœuds terminaux, jouant un rôle d’élagage implicite), splitrule (critère de séparation, gini ou extratrees), ainsi que mtry (nombre de variables candidates par split). Ces paramètres ont été optimisés à l’aide de notre schéma de validation. Les résultats montrent que la performance est maximale pour la configuration suivante : mtry = 2, splitrule = extratrees et min.node.size = 1, avec une AUC de 0,801. Cette combinaison favorise la diversité des arbres (faible mtry), des séparations plus aléatoires (extratrees) et une granularité plus fine (nœuds très petits), ce qui améliore la capacité de discrimination du modèle. À l’inverse, lorsque mtry augmente ou que min.node.size devient trop élevé, l’AUC décroît car la forêt perd en diversité et en précision. Le modèle optimal retenu permet ainsi de maximiser la détection des souscripteurs tout en maintenant un bon équilibre entre sensibilité (0,740) et spécificité (0,741).

## Sélection du modèle le plus optimal

```{r}
auc_rf <- max(rf_fit$results$ROC)
auc_rg <- max(rg_fit$results$ROC)

cat("AUC RandomForest :", round(auc_rf, 4), "\n")
cat("AUC Ranger       :", round(auc_rg, 4), "\n")

if (auc_rf >= auc_rg) {
  best_model <- rf_fit
  model_name <- "Random Forest (package randomForest)"
} else {
  best_model <- rg_fit
  model_name <- "Ranger (package ranger)"
}

cat("==> Modèle retenu :", model_name, "\n")
cat("Hyperparamètres optimaux :\n")
print(best_model$bestTune)
```
La comparaison des deux implémentations met en évidence que la forêt aléatoire (randomForest) atteint une AUC maximale de 0,796, tandis que l’implémentation Ranger obtient un score légèrement supérieur, à 0,802. Bien que l’écart soit limité, il souligne l’intérêt de Ranger, qui offre une plus grande flexibilité dans l’ajustement des hyperparamètres. Le modèle optimal retenu correspond à la configuration mtry = 2, splitrule = extratrees et min.node.size = 1. Ce paramétrage favorise une forte diversité entre les arbres et améliore la capacité discriminante de la forêt sur un jeu de données déséquilibré. Ainsi, le modèle Ranger est jugé plus performant et mieux adapté pour la suite de l’analyse, puisqu’il maximise la détection des souscripteurs tout en conservant une bonne généralisation.

## Evaluation sur le jeu de test

```{r}
pred_prob_rf <- predict(rf_fit, newdata = test, type = "prob")[, "yes"]
pred_prob_rg <- predict(rg_fit, newdata = test, type = "prob")[, "yes"]

pred_cls_rf <- factor(ifelse(pred_prob_rf >= 0.5, "yes", "no"), levels = c("no","yes"))
pred_cls_rg <- factor(ifelse(pred_prob_rg >= 0.5, "yes", "no"), levels = c("no","yes"))

cm_rf <- confusionMatrix(pred_cls_rf, test[[target_col]], positive = "yes")
cm_rg <- confusionMatrix(pred_cls_rg, test[[target_col]], positive = "yes")

cat("=== RandomForest ===\n")
print(cm_rf)
cat("\n=== Ranger ===\n")
print(cm_rg)

roc_rf <- pROC::roc(response = test[[target_col]], predictor = pred_prob_rf,
                    levels = c("no","yes"), direction = "<")
roc_rg <- pROC::roc(response = test[[target_col]], predictor = pred_prob_rg,
                    levels = c("no","yes"), direction = "<")

auc_rf <- pROC::auc(roc_rf)
auc_rg <- pROC::auc(roc_rg)

cat("\nAUC RandomForest (test) :", round(auc_rf, 3), "\n")
cat("AUC Ranger (test)       :", round(auc_rg, 3), "\n")

plot(roc_rf, legacy.axes = TRUE, col = "blue",
     main = "Courbes ROC sur le jeu de test - RandomForest vs Ranger")
plot(roc_rg, add = TRUE, col = "red")
legend("bottomright",
       legend = c(paste0("RandomForest AUC=", round(auc_rf,3)),
                  paste0("Ranger AUC=", round(auc_rg,3))),
       col = c("blue", "red"), lty = 1, cex = 0.9)
```
L’évaluation finale sur le jeu de test montre que les deux implémentations de forêts aléatoires obtiennent des performances très proches : une AUC de 0,825 pour RandomForest et de 0,821 pour Ranger. Ce résultat nuance l’analyse précédente, où Ranger apparaissait comme le plus performant en validation croisée. L’écart observé reste faible et non significatif, ce qui confirme la robustesse des deux approches face au problème étudié. Le choix final peut donc s’appuyer sur des critères pratiques : Ranger offre davantage de flexibilité dans le réglage des hyperparamètres, tandis que RandomForest affiche une légère supériorité sur le test. Dans les deux cas, la capacité de discrimination est jugée satisfaisante.

L’analyse des matrices de confusion montre que RandomForest atteint une accuracy de 77,2 %, avec une sensibilité de 0,799 et une spécificité de 0,763. De son côté, Ranger présente une accuracy et une une spécificité inférieures, mais leurs sensibilités sont similaires. Dans les deux cas, la capacité à repérer correctement les clients susceptibles de souscrire reste satisfaisante. Cet aspect est particulièrement important dans notre contexte marketing. Il est préférable de détecter un maximum de souscripteurs potentiels, quitte à inclure par erreur certains clients qui ne s’abonneront finalement pas.

Ces résultats confirment que les deux méthodes sont robustes et adaptées, mais montrent également que le gain de performance de Ranger observé en validation croisée ne se retrouve pas de manière significative sur le jeu de test. Le choix entre les deux implémentations peut donc se fonder sur des critères pratiques. Par exemple, RandomForest offre des performances légèrement supérieures en AUC et en spécificité, tandis que Ranger reste intéressant pour sa flexibilité dans l’optimisation des hyperparamètres.

## Importance des variables
```{r}

# Importance des variables - RandomForest
varImp_rf <- varImp(rf_fit, scale = TRUE)
print(varImp_rf)
plot(varImp_rf, top = 15, main = "Importance des variables - RandomForest")

varImp_rg <- varImp(rg_fit, scale = TRUE)
print(varImp_rg)
plot(varImp_rg, top = 15, main = "Importance des variables - Ranger")
```
L’analyse de l’importance des variables met en évidence des résultats cohérents entre les deux implémentations de forêts aléatoires. Dans les deux cas, la variable poutcome apparaît comme la plus déterminante dans la prédiction de la souscription à un dépôt à terme.

La variable housing arrive en seconde position, suivie de loan, de l’âge et du solde du compte. Ces variables traduisent des facteurs socio-économiques influençant directement la probabilité d’épargne ou de souscription.

Les variables marital, education, contact et default ont une importance plus faible, mais contribuent néanmoins à affiner le modèle en segmentant les profils. La cohérence entre RandomForest et Ranger renforce la robustesse de l’interprétation, bien que l’ordre exact des variables secondaires varie légèrement.

En conclusion, ces résultats montrent que l’historique des interactions marketing (poutcome) et les variables financières liées aux crédits et au patrimoine (housing, loan, balance) constituent les principaux déterminants de la souscription, ce qui est cohérent avec les attentes d’un ciblage marketing bancaire.















































