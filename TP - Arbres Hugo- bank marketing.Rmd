---
title: "TP - Abres de décision et forêts aléatoires"
author: "Enzo Munoz - Hugo Munier - Maxime Guilbaud"
date: "2025-10-21"
output:
  pdf_document:
    latex_engine: xelatex
  html_document:
    html_document:
    toc: true
    toc_float: true
    theme: cosmo
header-includes:
  - \usepackage{float}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(
  fig.width = 7,        
  fig.height = 4.5,
  out.width = "90%",    
  fig.align = "center", 
  fig.pos = "H"       
)
knitr::opts_chunk$set(
  message = FALSE,   
  warning = FALSE    
)
```

```{r}
# Bibliothèques utilisées

#install.packages("ggcorrplot")
#install.packages("GGally")
#install.packages("corrplot")
library(GGally)
library(ggplot2)
library(ggcorrplot)
library(corrplot)
```

```{r}
# Importation des données

data <- read.csv("C:/Users/hugom/OneDrive - Aescra Emlyon Business School/Mines de Saint-Etienne/3A/Science des données/Arbres de décision et forêts aléatoires/TP/7 bank_marketing.csv", 
                 sep=";", header=TRUE)
head(data)
summary(data)
```

```{r}
# valeurs manquantes
print("=== Nombre de NA par variable ===")
colSums(is.na(data))
print("=== Nombre de 'unknown' par variable ===")
sapply(data, function(x) sum(x == "unknown", na.rm=TRUE))
```

```{r}
# Transformation en facteur
factor_vars <- c("marital", "education", "contact", "poutcome", "default", "housing", "loan", "class")
data[factor_vars] <- lapply(data[factor_vars], as.factor)

# Transformation en numérique
numeric_vars <- c("balance", "age")
data[numeric_vars] <- lapply(data[numeric_vars], as.numeric)

# Vérification
str(data)
summary(data)
```
```{r}
# Analyse univariée
hist(data$age,
     main = "Distribution de l'âge",
     xlab = "Âge",
     col = "skyblue",
     border = "white",
     breaks = 20)

hist(data$balance,
     main = "Distribution du solde (balance)",
     xlab = "Balance (€)",
     col = "orange",
     border = "white",
     breaks = 50,
     xlim = c(-5000, 10000))

boxplot(data$age,
        main = "Boxplot de l'âge",
        col = "skyblue",
        horizontal = TRUE)

boxplot(data$balance,
        main = "Boxplot du solde (balance)",
        col = "orange",
        horizontal = TRUE)


for (var in factor_vars) {
  print(
    ggplot(data, aes_string(x = var, fill = var)) +
      geom_bar() +
      labs(title = paste("Répartition de", var),
           x = var,
           y = "Effectifs") +
      theme_minimal() +
      theme(legend.position = "none")
  )
}
```

```{r}
# Analyse bivariée

ggplot(data, aes(x = class, y = age, fill = class)) +
  geom_boxplot() +
  labs(title = "Boxplot de l'âge par classe",
       x = "Classe (Souscription dépôt à terme)",
       y = "Âge") +
  theme_minimal()

ggplot(data, aes(x = age, fill = class)) +
  geom_density(alpha = 0.5) +
  labs(title = "Densité de l'âge selon la classe",
       x = "Âge", y = "Densité") +
  theme_minimal()

ggplot(data, aes(x = class, y = balance, fill = class)) +
  geom_boxplot() +
  labs(title = "Boxplot du solde (balance) par classe",
       x = "Classe (Souscription dépôt à terme)",
       y = "Solde du compte (€)") +
  theme_minimal()

boxplot(balance ~ class, 
        data = data,
        main = "Distribution du solde par classe (zoom)",
        xlab = "Classe (Souscription dépôt à terme)",
        ylab = "Solde (€)",
        col = c("orange", "skyblue"),
        ylim = c(-2000, 10000))

table(data$marital, data$class)
prop.table(table(data$marital, data$class), margin = 1)

# Barplot empilé

ggplot(data, aes(x = marital, fill = class)) +
  geom_bar(position = "fill") +
  labs(title = "Taux de souscription selon marital",
       x = "Situation maritale", y = "Proportion") +
  scale_y_continuous(labels = scales::percent) +
  theme_minimal()

table(data$education, data$class)
prop.table(table(data$education, data$class), margin = 1)

ggplot(data, aes(x = education, fill = class)) +
  geom_bar(position = "fill") +
  labs(title = "Taux de souscription selon éducation",
       x = "Niveau d'éducation", y = "Proportion") +
  scale_y_continuous(labels = scales::percent) +
  theme_minimal()

for (var in c("housing", "loan", "default")) {
  print(table(data[[var]], data$class))
  print(prop.table(table(data[[var]], data$class), margin = 1))
  
  print(
    ggplot(data, aes_string(x = var, fill = "class")) +
      geom_bar(position = "fill") +
      labs(title = paste("Taux de souscription selon", var),
           x = var, y = "Proportion") +
      scale_y_continuous(labels = scales::percent) +
      theme_minimal()
  )
}

table(data$contact, data$class)
prop.table(table(data$contact, data$class), margin = 1)

ggplot(data, aes(x = contact, fill = class)) +
  geom_bar(position = "fill") +
  labs(title = "Taux de souscription selon type de contact",
       x = "Type de contact", y = "Proportion") +
  scale_y_continuous(labels = scales::percent) +
  theme_minimal()

table(data$poutcome, data$class)
prop.table(table(data$poutcome, data$class), margin = 1)

ggplot(data, aes(x = poutcome, fill = class)) +
  geom_bar(position = "fill") +
  labs(title = "Taux de souscription selon résultat campagne précédente",
       x = "Résultat précédent", y = "Proportion") +
  scale_y_continuous(labels = scales::percent) +
  theme_minimal()
```

```{r}
numeric_data <- data[, numeric_vars]

cat_vars <- c("marital", "education", "default", "housing", "loan", "contact", "poutcome","class")
dummies <- dummyVars(~ ., data = data[, cat_vars])
cat_data <- data.frame(predict(dummies, newdata = data))

data_corr <- cbind(numeric_data, cat_data)
cor_matrix <- cor(data_corr, use = "complete.obs")

plot_df <- cbind(data_corr, class = data$class)

vars_to_plot <- c("age", "balance", "marital.married", "marital.divorced","marital.single", "education.tertiary", "housing.yes", "loan.yes", "poutcome.success")

ggcorrplot(cor_matrix,
           hc.order = TRUE, 
           type = "lower",
           lab = FALSE,          
           lab_size = 2.5,
           colors = c("red", "white", "blue"),
           title = "Matrice de corrélation")

corrplot(cor_matrix, method = "color", type = "upper",
         tl.cex = 0.7,
         title = "Matrice de corrélations")

ggpairs(plot_df,
        columns = vars_to_plot,
        aes(color = class, alpha = 0.6),
        upper = list(continuous = "points"),
        title = "Matrice de dispersion - variables clés")

```
## PARTIE II - Foret aléatoire


```{r}
library(tidyverse)
library(data.table)
library(janitor)
library(skimr)
library(caret)
library(pROC)
library(randomForest)
library(ranger)
library(rpart)
library(rpart.plot)
```
## Split Apprentissage
```{r}
target_col <- "class"
levels(data[[target_col]])

x_cols <- setdiff(names(data), target_col)

set.seed(1234)
idx <- createDataPartition(data[[target_col]], p = 0.8, list = FALSE)
train <- data[idx, ]
test  <- data[-idx, ]

dim(train)
dim(test)

prop.table(table(train[[target_col]]))
prop.table(table(test[[target_col]]))
```
Afin d’évaluer la performance des modèles de manière robuste, nous avons séparé l’échantillon en un jeu d’apprentissage (80 %, soit 6 292 observations) et un jeu de test (20 %, soit 1 572 observations). Les résultats montrent que la répartition des classes est parfaitement équilibrée entre les deux sous-ensembles : environ 77 % des clients n’ont pas souscrit (“no”) et 23 % ont souscrit (“yes”), aussi bien dans le jeu d’apprentissage que dans le jeu de test. Cette étape garantit que l’échantillon de test est représentatif et qu’il permettra d’évaluer correctement la capacité de généralisation des modèles. Elle est particulièrement importante dans ce contexte où la classe positive (“yes”) est minoritaire, car elle assure que les indicateurs de performance (accuracy, précision, rappel, AUC) pourront être interprétés de façon fiable sans biais lié au déséquilibre des données.

## Schéma de validation et métriques

```{r}
ctrl <- trainControl(
  method = "repeatedcv",
  number = 5, repeats = 2,
  classProbs = TRUE,
  summaryFunction = twoClassSummary,
  sampling = "down",
  savePredictions = "final"
)
```
Pour évaluer et comparer les modèles de forêts aléatoires, nous avons adopté un schéma de validation croisée robuste. Le jeu d’apprentissage a été soumis à une validation croisée à 5 folds, répétée 2 fois afin de réduire la variance des estimations. Comme la variable cible est déséquilibrée (77 % “no” contre 23 % “yes”), un down-sampling a été appliqué dans chaque fold pour rééquilibrer les classes et éviter un apprentissage biaisé. Les modèles ont été évalués selon plusieurs indicateurs : l’AUC/ROC, qui mesure la capacité globale de discrimination, la sensibilité (rappel) pour juger la détection des souscriptions effectives, et la spécificité pour contrôler les faux positifs. Après sélection du meilleur modèle sur ce protocole, une évaluation finale est conduite sur le jeu de test indépendant afin de mesurer sa capacité de généralisation à de nouvelles données.

## Arbre de décision illustratif
```{r}
model_tree <- rpart(class ~ ., data = train, method = "class")
rpart.plot(model_tree, type=2, extra=104, main="Arbre de décision")
```
L’arbre de décision simple met en évidence le rôle central de la variable poutcome (résultat de la campagne précédente) dans la prédiction. Lorsque poutcome est “failure” ou “other”, la probabilité de non-souscription est très élevée (86 %), tandis qu’elle s’inverse lorsque l’issue est différente, avec une majorité de souscriptions (65 %). Cet arbre illustre bien la logique de segmentation, mais reste limité car il ne capture qu’une règle principale et demeure instable. Pour obtenir un modèle plus robuste et généralisable, il est donc nécessaire de recourir à une forêt aléatoire, combinaison de nombreux arbres.

## Implémentation A
```{r}
grid_rf <- expand.grid(
  mtry = floor(seq(2, sqrt(length(x_cols))*2, length.out = 6))
)

set.seed(1234)
rf_fit <- train(
  x = train[, x_cols],
  y = train[[target_col]],
  method = "rf",
  metric = "ROC",
  trControl = ctrl,
  tuneGrid = grid_rf,
  ntree = 500,
  importance = TRUE
)

print(rf_fit)

plot(rf_fit, main = "Performance ROC en fonction de mtry (Random Forest)")
```
Pour l’implémentation Random Forest, nous avons testé différentes valeurs de l’hyperparamètre mtry, correspondant au nombre de variables candidates sélectionnées aléatoirement à chaque division de nœud. L’évaluation a été réalisée par validation croisée à 5 folds, répétée deux fois, avec un équilibrage par down-sampling pour compenser le déséquilibre entre classes. Les résultats montrent que la performance, mesurée par l’AUC (ROC), décroît lorsque mtry augmente : elle atteint un maximum à mtry = 2 avec une AUC de 0,796, puis diminue progressivement jusqu’à 0,761 pour mtry = 6. Cette tendance s’explique par le fait qu’un nombre trop élevé de variables testées à chaque split réduit la diversité des arbres et favorise le sur-apprentissage. Le modèle optimal retenu est donc celui avec mtry = 2, qui offre le meilleur compromis entre sensibilité (0,761) et spécificité (0,721). Ce réglage maximise la capacité discriminante de la forêt aléatoire et améliore la détection des souscripteurs, objectif prioritaire de notre étude.

## Imlplémentation B
```{r}
grid_rg <- expand.grid(
  mtry = floor(seq(2, sqrt(length(x_cols))*2, length.out = 6)),
  splitrule = c("gini", "extratrees"),
  min.node.size = c(1, 5, 10)     
)

set.seed(1234)
rg_fit <- train(
  x = train[, x_cols],
  y = train[[target_col]],
  method = "ranger",
  metric = "ROC",
  trControl = ctrl,
  tuneGrid = grid_rg,
  num.trees = 800,
  importance = "permutation",
  respect.unordered.factors = "partition"
)

print(rg_fit)

plot(rg_fit, main = "Performance ROC selon hyperparamètres (Ranger)")
```
Pour l’implémentation Ranger, nous avons choisi cette méthode car elle est plus rapide que randomForest, gère efficacement les grands volumes de données et offre davantage de possibilités de réglage des hyperparamètres. Contrairement à un arbre de décision unique qui nécessite un élagage explicite, Ranger permet de contrôler la complexité de chaque arbre via des paramètres comme min.node.size (taille minimale des nœuds terminaux, jouant un rôle d’élagage implicite), splitrule (critère de séparation, gini ou extratrees), ainsi que mtry (nombre de variables candidates par split). Ces paramètres ont été optimisés grâce à une validation croisée répétée 5×2, avec down-sampling pour compenser le déséquilibre entre les classes.

Les résultats montrent que la performance (AUC) est maximale pour mtry = 2, splitrule = extratrees et min.node.size = 1, avec une AUC de 0,801. Ce résultat confirme que, dans ce jeu de données, favoriser une forte diversité des arbres (faible mtry, règle de séparation plus aléatoire, nœuds très fins) permet d’améliorer la capacité de discrimination du modèle. Comparativement aux autres configurations, l’AUC décroît lorsque mtry augmente ou lorsque min.node.size devient trop grand, car la forêt perd en granularité et en diversité. Le modèle optimal retenu maximise la détection des clients souscripteurs, objectif central de l’étude marketing, tout en conservant une sensibilité (0,740) et une spécificité (0,741) équilibrées.

## Sélection du modèle le plus optimal

```{r}
auc_rf <- max(rf_fit$results$ROC)
auc_rg <- max(rg_fit$results$ROC)

cat("AUC RandomForest :", round(auc_rf, 4), "\n")
cat("AUC Ranger       :", round(auc_rg, 4), "\n")

if (auc_rf >= auc_rg) {
  best_model <- rf_fit
  model_name <- "Random Forest (package randomForest)"
} else {
  best_model <- rg_fit
  model_name <- "Ranger (package ranger)"
}

cat("==> Modèle retenu :", model_name, "\n")
cat("Hyperparamètres optimaux :\n")
print(best_model$bestTune)
```
La comparaison des deux implémentations montre que la forêt aléatoire classique (randomForest) atteint une AUC maximale de 0,796, tandis que l’implémentation ranger obtient une AUC légèrement supérieure, à 0,802. Même si l’écart reste modeste, il confirme l’intérêt de ranger, qui combine une plus grande flexibilité dans le réglage des hyperparamètres et une efficacité computationnelle accrue. Le modèle optimal retenu est donc la forêt aléatoire entraînée avec ranger, configurée avec mtry = 2 (nombre de variables candidates à chaque split), la règle de séparation extratrees (qui favorise la diversité des arbres) et une taille minimale de nœud de 1 (arbres plus fins et expressifs). Ce réglage maximise la diversité entre arbres et permet d’améliorer la capacité discriminante de la forêt sur un problème déséquilibré. Ainsi, le modèle ranger est jugé plus performant et mieux adapté pour la suite de l’analyse, car il maximise la détection des clients susceptibles de souscrire tout en conservant une bonne capacité de généralisation.

## Evaluation sur le jeu de test

```{r}
pred_prob_rf <- predict(rf_fit, newdata = test, type = "prob")[, "yes"]
pred_prob_rg <- predict(rg_fit, newdata = test, type = "prob")[, "yes"]

pred_cls_rf <- factor(ifelse(pred_prob_rf >= 0.5, "yes", "no"), levels = c("no","yes"))
pred_cls_rg <- factor(ifelse(pred_prob_rg >= 0.5, "yes", "no"), levels = c("no","yes"))

cm_rf <- confusionMatrix(pred_cls_rf, test[[target_col]], positive = "yes")
cm_rg <- confusionMatrix(pred_cls_rg, test[[target_col]], positive = "yes")

cat("=== RandomForest ===\n")
print(cm_rf)
cat("\n=== Ranger ===\n")
print(cm_rg)

roc_rf <- pROC::roc(response = test[[target_col]], predictor = pred_prob_rf,
                    levels = c("no","yes"), direction = "<")
roc_rg <- pROC::roc(response = test[[target_col]], predictor = pred_prob_rg,
                    levels = c("no","yes"), direction = "<")

auc_rf <- pROC::auc(roc_rf)
auc_rg <- pROC::auc(roc_rg)

cat("\nAUC RandomForest (test) :", round(auc_rf, 3), "\n")
cat("AUC Ranger (test)       :", round(auc_rg, 3), "\n")

plot(roc_rf, legacy.axes = TRUE, col = "blue",
     main = "Courbes ROC sur le jeu de test - RandomForest vs Ranger")
plot(roc_rg, add = TRUE, col = "red")
legend("bottomright",
       legend = c(paste0("RandomForest AUC=", round(auc_rf,3)),
                  paste0("Ranger AUC=", round(auc_rg,3))),
       col = c("blue", "red"), lty = 1, cex = 0.9)
```
L’évaluation finale sur le jeu de test montre que les deux implémentations de forêts aléatoires atteignent des performances proches, avec une AUC de 0,825 pour RandomForest et 0,821 pour Ranger. Ces valeurs indiquent une bonne capacité de discrimination entre les clients susceptibles de souscrire et ceux qui ne souscrivent pas. En termes de matrice de confusion, RandomForest obtient une accuracy de 77,2 % avec une sensibilité de 0,799 et une spécificité de 0,763, tandis que Ranger présente une accuracy légèrement inférieure (75,9 %) mais une sensibilité comparable (0,802) et une spécificité un peu plus faible (0,747). Dans les deux cas, le rappel (sensibilité) est satisfaisant, ce qui est essentiel dans notre contexte marketing où l’objectif est de maximiser la détection des souscripteurs (“yes”), même au prix d’un plus grand nombre de faux positifs.

Ces résultats confirment que les deux méthodes sont robustes et adaptées à la problématique, mais montrent également que le gain de performance de Ranger observé en validation croisée ne se retrouve pas de manière significative sur le jeu de test. Le choix entre les deux implémentations peut donc se fonder sur des critères pratiques : RandomForest offre des performances légèrement supérieures en AUC et en spécificité, tandis que Ranger reste intéressant pour sa rapidité d’exécution et sa flexibilité dans l’optimisation des hyperparamètres.

## Importance des variables
```{r}

# Importance des variables - RandomForest
varImp_rf <- varImp(rf_fit, scale = TRUE)
print(varImp_rf)
plot(varImp_rf, top = 15, main = "Importance des variables - RandomForest")

varImp_rg <- varImp(rg_fit, scale = TRUE)
print(varImp_rg)
plot(varImp_rg, top = 15, main = "Importance des variables - Ranger")
```
L’analyse de l’importance des variables met en évidence des résultats cohérents entre les deux implémentations de forêts aléatoires. Dans les deux cas, la variable poutcome (résultat de la campagne marketing précédente) apparaît comme la plus déterminante dans la prédiction de la souscription à un dépôt à terme. Cela est intuitif : un client ayant déjà répondu favorablement à une campagne antérieure est beaucoup plus susceptible de souscrire à nouveau.

La variable housing (présence d’un crédit immobilier) arrive en seconde position, suivie de loan (crédit personnel), de l’âge et du solde du compte (balance). Ces variables traduisent des facteurs socio-économiques influençant directement la probabilité d’épargne ou de souscription : par exemple, un client ayant déjà un crédit immobilier ou personnel peut avoir une capacité de souscription réduite.

Les variables marital (situation familiale), education, contact et default ont une importance plus faible, mais contribuent néanmoins à affiner le modèle en segmentant les profils. La cohérence entre RandomForest et Ranger renforce la robustesse de l’interprétation, bien que l’ordre exact des variables secondaires varie légèrement.

Enfin, il est à noter que certaines variables fortement corrélées à la souscription mais uniquement observables après coup (comme duration dans d’autres versions du dataset) ne figurent pas ici. Cela évite tout biais de fuite d’information (data leakage) et garantit que l’interprétation repose sur des variables disponibles au moment de la décision.

En conclusion, ces résultats montrent que l’historique des interactions marketing (poutcome) et les variables financières liées aux crédits et au patrimoine (housing, loan, balance) constituent les principaux déterminants de la souscription, ce qui est cohérent avec les attentes d’un ciblage marketing bancaire.















































