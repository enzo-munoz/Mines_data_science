---
title: "TP3 Krigeage - Challenge 2025-2026"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Ce TP fera l’objet d’un compte-rendu par groupe de 3 à 5 personnes,
sous forme de Rmd + version pdf ou html. Ce compte-rendu servira à l’évaluation. Il est à remettre sur Campus (au lien de rendu TP) avant le 10 janvier 2026 à 23h59.
A titre indicatif, le temps à consacrer à ce TP hors cours est de deux à quatre heures par personne.

# Question 1. Vos noms

```{r}
#1. MUNOZ Enzo 
#2. MUNIER Hugo
#3. GUILBAUD Maxime
```

L'ordre n'a pas d'importance, mais la personne en position 1 sera celle qui remettra le TP sur Campus. Merci de n'opérer qu'une seule remise par groupe! Merci de nommer vos fichiers en faisant apparaître le premier nom, par exemple ici: `TPXXX_GroupeDURAND.Rmd`, `TPXXX_GroupeDURAND.html`

# Question 2. Votre prédiction


```{r seed}
library(DiceKriging)
library(caret)
library(FactoMineR)
```


```{r}

Observations = read.csv("defi_observations.csv", header = TRUE)
X<- Observations[,-8]
Y<- Observations[,8]
n<- length(Y)
d<- length(X)

X_new = read.csv("defi_apredire.csv", header = TRUE)
range_Y<- max(Y) - min(Y)
```

## Faire une analyse ACP !
```{r}
Y_scaled<- (Y - min(Y))/range_Y
obs<- cbind(X, Y_scaled)
res <- PCA(obs,
                   scale.unit = FALSE,   
                   ncp = 7,             
                   graph = TRUE) 
```
On ne peut pas conclure sur l'importance des variables, les 2 dimensions principales ne représentent que 35 % de l'information. 


```{r}
pairs(Observations)
```
Indépendance des X : Les croisements entre $X1...X7$ forment des carrés parfaits très denses. 

Cela indique que tes données d'entrée sont probablement issues d'un plan d'expérience (type Latin Hypercube Sampling), où les variables sont effectivement décorrélées entre elles.


```{r}
plot(X[,2], Y)
```

# Validation croisée pour la famille matern en krigeage simple !

J'utilise la bibliothèque caret pour que mon split soit automatiquement stratifié en fonction des quantiles de Y.

```{r}
set.seed(123456)

trainIndex <- createDataPartition(Y, p = 0.8, list = FALSE)

Xtrain <- X[trainIndex, ]
Xtest  <- X[-trainIndex, ]
Ytrain <- Y[trainIndex]
Ytest  <- Y[-trainIndex]

crossValidationError <- function(famille, theta) {

    monModele <- km(formula = ~1, design = Xtrain, response = Ytrain, covtype = famille, coef.trend = 0,  coef.cov = theta, coef.var = 1)
  prediction <- predict(object = monModele, newdata = Xtest , type="SK" , checkNames=FALSE, se.compute=FALSE)  

  error =  (mean((prediction$mean -Ytest)^2))   
  
  return(error)
}
theta_vec <- rep(1, d)

essai <- crossValidationError("matern3_2", theta_vec)
message("erreur =", essai)

```

### Analyse de la sensibilité et Optimisation Anisotrope

Peut-on optimiser avec le même theta selon toutes les directions tq : theta_optim = rep(theta, 7) ???

## Réponse Chat + Enzo

Sensibilité de Y : C'est là que ton hypothèse d'un $\theta$ unique tombe.$Y$ est fortement corrélé à $X1$ et $X2$ (on voit une structure linéaire/croissante très nette).$Y$ semble être du bruit total face à $X3, X4, X5, X6, X7$ (nuages informes).

Pourquoi $\theta$ ne peut PAS être le même ?

Le fait que les $X$ soient indépendants entre eux n'implique pas que $Y$ réagisse de la même façon à chaque $X$.$\theta_i$ représente la portée (ou "length-scale"). Plus $\theta_i$ est grand, plus la variable $X_i$ est considérée comme "lisse" ou peu influente localement.

Ici, comme $X1$ et $X2$ expliquent presque toute la variation de $Y$, le modèle aura besoin de $\theta$ précis pour ces dimensions. 

Pour les autres ($X3...X7$), l'optimiseur risque de pousser les $\theta$ vers des valeurs très grandes pour "lisser" leur absence d'influence.

Conclusion : Tu as besoin d'un modèle anisotrope (un $\theta$ par dimension).

Résumé : Au vu du graphique `pairs()`, on observe une forte dépendance de $Y$ envers $X1$ et $X2$, tandis que les autres variables semblent peu influentes. Utiliser un $\theta$ unique (modèle isotrope) masquerait cette réalité physique.

```{r optimisation-anisotrope}

# 1. Définition de la fonction d'erreur pour 7 portées différentes
objective_anisotrope <- function(theta_vec) {
  # On s'assure que theta_vec a bien une longueur de 7
  val <- tryCatch({
    crossValidationError(famille = "matern3_2", theta = theta_vec)
  }, error = function(e) return(Inf))
  return(val)
}

# 2. Configuration de l'optimiseur
# On part d'un theta de 1 pour chaque dimension
theta_start <- rep(1, 7)
lower_b <- rep(0.01, 7)
upper_b <- rep(20, 7) # On laisse une plage large

# 3. Recherche des meilleurs paramètres
opt_res <- optim(par = theta_start, 
                 fn = objective_anisotrope, 
                 method = "L-BFGS-B", 
                 lower = lower_b, 
                 upper = upper_b,
                 control = list(maxit = 100)) # "maxit" bride le temps de calcul

# 4. Affichage des résultats pour preuve
df_thetas <- data.frame(
  Variable = paste0("X", 1:7),
  Theta_Optimal = opt_res$par
)

print(df_thetas)


```

Les thetas pour X3, X6, X5 sont égal à l'upper bound et X7 avec 17,8. Qu'est ce que ça signifie ? 
Peut-on les supprimer ? Même pour X4 theta = 6.53 indique pour matern 3/2 que le modèle considère que tous les points sont proches et ça revient à ignorer les variations de $Xi$.

On pense donc pour la suite, faire une méthode de krigeage ordinaire et universel avec d'autre kernel. 

Optim.method pour laisser chercher les hyperparamètres directement dans la fonction dicekriging.


```{r}
modele <- km(design=X_train, response=Y_train, covtype="matern3_2",
             optim.method = "BFGS", 
             control = list(maxit = 30)) # Maximum 30 itérations

```


# Consignes

Vous trouverez dans le répertoire de Campus un fichier intitulé "defi_observations.csv", il comporte des observations pour 7 variables X1, ..., X7, et une variable à prédire Y.

Vous trouverez également dans le répertoire du cours un fichier intitulé "defi_apredire.csv" comportant des valeurs pour les 6 variables X1, ..., X7, et où il faudra prédire Y.

* Remettre vos prédictions dans un fichier csv comportant les 7 variables X1, ..., X7, et la colonne Y prédite. Votre fichier s'intitulera "DefiGroupeXXX" où vous remplacerez le suffixe XXX par le nom de la personne indiquée en position 1 à la question 1, celle qui remettra le TP sur Campus.
Pour l'exemple ci-dessus le nom du fichier serait "DefiGroupeDURAND.csv". Merci de nommer les variables X1, ..., X7 et Y pour la colonne prédite.

* Le programme à l'origine de vos prédictions sera initulé "programmeDefiGroupeXXX" (en remplaçant XXX...). Il est attendu un programme sour format Rmd+ sortie Html ou pdf correspondante (bouton Knit, ou bien Python+Jupyter Notebook avec sortie html ou pdf).

La contrainte: la prédiction doit se faire au moyen du Krigeage (eh oui, c'est un TP de Krigeage), mais vous pouvez utiliser des éléments de régression aussi (cf. Krigeage universel).

ATTENTION! il vous faudra faire attention à bien utiliser une graine pour votre générateur aéatoire, si vous en utilisez un, p.ex `set.seed(123456)` de façon à ce que vos résultats soit reproductibles. D'une exécution à l'autre, votre programme doit proposer LA MEME prédiction!

Vérifiez bien que votre fichier "DefiGroupeXXX.csv" comporte bien le bon nombre de lignes, et des abscisses dans le bon ordre!

Veillez à remettre impérativement ces trois fichiers:

* Le fichier CSV DefiGroupeXXX.csv
* Un notebook Rmd (ou jupyter)
* la sortie html ou pdf correspondante (bouton knit) faisant tourner votre programme


```{r import export données}
# ce qui est donné:

# Votre prédiction; faites mieux, hein ;-)
Y = Apredire$X1 + mean(Observations$Y)
# votre Y prédit ici X1 + la moyenne des Y, c'est très mauvais!

# Votre exportation
# On concatène d'abord les X avec le Y prédit à l'aide de cbind
MonFichierSoumis =  cbind(Apredire, Y)

# puis on exporte
MonNomDeFichier = "DefiGroupeDURAND.csv" # nom de fichier à adapter hein!!!
write.csv(MonFichierSoumis, MonNomDeFichier, row.names = FALSE)

#on vérifie que c'est bien lisible
LectureDeMonFichier = read.csv(MonNomDeFichier, header = TRUE)

#on fait des vérifications élémentaires, bon nombre de lignes, de colonnes, etc.
#on ne doit voir apparaître que des TRUE, sinon ce n'est pas bon!
message(nrow(LectureDeMonFichier) == 100, ": bon nombre de lignes")
message(ncol(LectureDeMonFichier) == 8, ": bon nombre de colonnes")
message(abs(LectureDeMonFichier[37,3]-Apredire[37,3])<1e-6, ": X3 semble ok pour la ligne 37")
message(sum(colnames(LectureDeMonFichier)==c("X1", "X2", "X3", "X4", "X5", "X6", "X7", "Y")) == 8, ": les colonnes sont bien nommées")
```

Voilà, c'est à vous, vous n'avez plus qu'à faire vos prédictions! en remplaçant la ligne `Y = Apredire$X1 + mean(Observations$Y)` bien sûr!

Bon courage!

