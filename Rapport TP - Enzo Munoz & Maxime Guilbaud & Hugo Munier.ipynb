{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "754759da-39de-4634-a5aa-e6fa119bb1bb",
   "metadata": {},
   "source": [
    "# OBJECTIF\n",
    "\n",
    "L'objectif de ce TP est de montrer que, pour différentes lois de probabilité et différentes méthodes déscente de gradient, l'espérance d'un vecteur aléaroire se dévoile comme la solution d'un problème d'optimisation, et à comparer empiriquement les convergences de nos modèles. \n",
    "\n",
    "# DEMONSTRATION\n",
    "\n",
    "Soit $X=(X_1,\\dots,X_d)$ un vecteur aléatoire à valeurs dans $\\mathbb{R}^d$.\n",
    "On considère la fonction objectif\n",
    "$$\n",
    "f(x_1,\\dots,x_d)\n",
    "= \\mathbb{E}\\big[(X_1-x_1)^2+\\cdots+(X_d-x_d)^2\\big].\n",
    "$$\n",
    "\n",
    "Pour une réalisation de $X$, un gradient bruité de $f$ en $(x_1,\\dots,x_d)$ est donné par :\n",
    "$$\n",
    "\\big(-2(X_1-x_1),\\dots,-2(X_d-x_d)\\big).\n",
    "$$\n",
    "\n",
    "On a donc, en prenant l'espérance :\n",
    "$$\n",
    "\\nabla f(x_1,\\dots,x_d)\n",
    "= \\mathbb{E}\\big[(-2(X_1-x_1),\\dots,-2(X_d-x_d))\\big].\n",
    "$$\n",
    "D'où\n",
    "$$\n",
    "\\nabla f(x_1,\\dots,x_d)\n",
    "= -2\\big(\\mathbb{E}[X_1]-x_1,\\dots,\\mathbb{E}[X_d]-x_d\\big).\n",
    "$$\n",
    "\n",
    "En posant $x\\in\\mathbb{R}^d$ avec $x=(x_1,\\dots,x_d)$, on peut écrire :\n",
    "$$\n",
    "\\nabla f(x)=2\\big(x-\\mathbb{E}[X]\\big).\n",
    "$$\n",
    "\n",
    "Pour trouver un minimum de $f$, on résout :\n",
    "$$\n",
    "\\nabla f(x)=0\n",
    "\\quad \\Longleftrightarrow \\quad\n",
    "2\\big(x-\\mathbb{E}[X]\\big)=0\n",
    "\\quad \\Longleftrightarrow \\quad\n",
    "x=\\mathbb{E}[X].\n",
    "$$\n",
    "Ainsi, $\\mathbb{E}[X]$ est un point critique de $f$.\n",
    "\n",
    "De plus, la Hessienne de $f$ vaut :\n",
    "$$\n",
    "\\nabla^2 f(x)=2I_d,\n",
    "$$\n",
    "où $I_d$ est la matrice identité en dimension $d$.\n",
    "Comme $2I_d$ est définie positive, $f$ est strictement convexe sur $\\mathbb{R}^d$.\n",
    "Le point critique est donc un minimum global unique.\n",
    "\n",
    "Finalement, le minimiseur de\n",
    "$$\n",
    "f(x)=\\mathbb{E}\\big[(X_1-x_1)^2+\\cdots+(X_d-x_d)^2\\big]\n",
    "$$\n",
    "est exactement\n",
    "$$\n",
    "\\boxed{x^\\star=\\mathbb{E}[X]}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f254b40f-666f-4945-a894-5eb3395493bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
