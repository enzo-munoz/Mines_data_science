---
title: "tp_serie_temporelle"
output:
  html_document: default
  pdf_document: default
date: "2025-10-02"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE)
```

## Contexte du TP


```{r, echo=FALSE}
library (tseries)
library(FinTS)
library(rugarch)
library(Metrics)
library(forecast)
library(dplyr)
library(tidyr)
library(lubridate)
library(forecast)
library(tseries)
library(ggplot2)
library(gridExtra)
library(moments)
library(psych)


```

```{r, echo = FALSE}

data <- read.csv("data.csv", stringsAsFactors = FALSE)

#head(data)
#str(data)

data$temp_C <- (data$TAVG..Degrees.Fahrenheit. - 32)/1.8

#head(data[,c("TAVG..Degrees.Fahrenheit.","temp_C")])

data$Date <- as.Date(data$Date, format="%m/%d/%Y") #Convertir la colonne en objet Date

data_mensuelle <- data %>%
  mutate (mois = floor_date(Date, "month")) %>%
  group_by(mois) %>%
  summarise(T_moy = mean(temp_C, na.rm = TRUE))

head(data_mensuelle)

```
Les données journalières de température à Lyon entre 1990 et 2025 ont été importées avec succès et converties de °F en °C.
Elles ont ensuite été agrégées en moyennes mensuelles, donnant une série temporelle de fréquence 12.
La série montre une saisonnalité annuelle très nette, avec des pics estivaux (≈ juillet–août) et des creux hivernaux (≈ janvier).
L’amplitude des variations saisonnières est d’environ 20°C, stable au fil des années.

```{r, echo = FALSE}

temperature <- (ts(data_mensuelle$T_moy, start = c(1990,1), frequency = 12))
len<- length(temperature)
moyenne <- mean(temperature, na.rm = TRUE)
mediane <- median(temperature, na.rm = TRUE)
variance <- var(temperature, , na.rm = TRUE)
asymetrie <- skewness(temperature, na.rm = TRUE)
aplatissement <- kurtosis(temperature, na.rm = TRUE)

```
Le nombre totale de mois observé est 427 entre Janvier 1990 et Juillet 2025. 
```{r, echo = FALSE}
stats_df <- data.frame(
  Statistique = c("Moyenne", "Médiane", "Variance", "Skewness (asymétrie)", "Kurtosis (aplatissement)"),
  Valeur = c(moyenne, mediane, variance, asymetrie, aplatissement)
)

knitr::kable(
  stats_df,
  caption = "Statistiques descriptives de la série temporelle",
  digits = 3
)
```


```{r, echo = FALSE}
plot(temperature,
     main = " Température moyenne mensuelle à Lyon",
     xlab = "Année",
     ylab = "Température (°C)",
     col = "blue",
     lwd = 2)
grid()
mu<- mean(temperature)

abline(h = mu, col = "red", lty = 2, lwd = 2)
legend("topleft", legend = "Moyenne", col = "red", lty = 2, lwd = 2, bty = "n")

```

La série temporelle présente une moyenne d’environ 13,2°C et une médiane proche (12,6°C), ce qui suggère une distribution globalement symétrique. 
La variance (47,2) indique une dispersion modérée des valeurs autour de la moyenne, avec un écart-type d’environ 7°C. 
Le skewness proche de zéro (0,04) confirme l’absence d’asymétrie marquée, tandis que le kurtosis inférieur à 3 (1,79) traduit une distribution plus aplatie que la normale, avec moins de valeurs extrêmes.

La série présente une forte saisonnalité annuelle (été chaud, hiver froid), avec une amplitude assez stable (~20°C). 
On peut suspecter une tendance légèrement haussière des températures maximales récentes, mais ce n’est pas flagrant visuellement. 

```{r, echo=FALSE}
# Extraire les mois (1 à 12)
months <- cycle(temperature)

df <- data.frame(Month = factor(months, levels = 1:12, labels = month.abb),
                 Temp = as.numeric(temperature))

# Tracer les boxplots par mois
ggplot(df, aes(x = Month, y = Temp)) +
  geom_boxplot(fill = "lightblue") +
  labs(title = "Distribution des températures par mois",
       x = "Mois",
       y = "Température (°C)") +
  theme_minimal()

ecart_type_par_mois <- df %>%
  group_by(Month) %>%
  summarise(Ecart_Type_Temp = sd(Temp))

# Création du graphique
ggplot(data = ecart_type_par_mois, aes(x = Month, y = Ecart_Type_Temp)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    title = "Écart type mensuel des températures",
    x = "Mois",
    y = "Écart type des températures"
  ) +
  theme_minimal()

```
La volatilité dépend du mois étudié. Sur le graphe on voit l'hétéroscélasticité des températures, notament un écart type plus important pour le mois de Janvier avec un écart type de 1.876471°C ou Février avec 2.472963°c contre un écart type de température plus faible pour les mois de Mars ou Avril (1.350898°C resp. 1.497665°C) par exemple.

```{r, echo=FALSE}
# Différenciation simple
ts_diff1 <- diff(temperature, differences = 1)

# Différenciation saisonnière
ts_diff_seas <- diff(temperature, lag = 12)

# Tests sur séries différenciées
par(mfrow = c(2, 2))
plot(temperature, main = "Série Originale", ylab = "Température", col = "blue", lwd = 1.5)
plot(ts_diff1, main = "Différenciation d = 1", ylab = "Diff(Température)", col = "red", lwd = 1.5)
abline(h = 0, lty = 2)
plot(ts_diff_seas, main = "Différenciation Saisonnière (lag=12)", 
     ylab = "Diff(Température)", col = "green4", lwd = 1.5)
abline(h = 0, lty = 2)

# ACF de la série différenciée
acf(ts_diff1, main = "ACF - Série Différenciée (d=1)", lag.max = 36)

# Test ADF sur série différenciée
adf_diff <- adf.test(ts_diff1)
cat("\nTest ADF après différenciation (d=1) :\n")
cat("p-value :", round(adf_diff$p.value, 4), "\n")
```
Afin d'analyser la stationnarité de la série, nous avons effectué un test de Dickey-Fuller augmenté sur la série préalablement différenciée à l'ordre 1. L'obtention d'une p-value de 0.01 nous permet de rejeter l'hypothèse de non stationnarité. L'examen de sa fonction d'autocorrélation (ACF) a cependant mis en évidence des pics périodiques significatifs, suggérant une composante saisonnière. Pour la suite de l'analyse, nous avons donc décidé de travailler avec la série corrigée de ses variations saisonnières avec un décalage de 12 périodes.

```{r, echo=FALSE}
des_data<- diff(temperature, lag=12)
plot(des_data, type='o', main = "Série désaisonnalisée par différenciation (lag 12)")
mu <- mean(des_data)
sig.des_data <- sd(des_data)
abline(h=mu, col="red", lwd=2)
abline(h=mu+2*sig.des_data, col="red", lwd=2,lty=2)
abline(h=mu-2*sig.des_data, col="red", lwd=2,lty=2)
grid()

```
Une première inspection visuelle de la série temporelle des températures ne révèle pas de tendance (trend) évidente. Afin de mieux comprendre la structure de dépendance temporelle et d'identifier la présence éventuelle de processus auto-régressifs (AR) ou de moyenne mobile (MA), nous allons maintenant procéder à l'analyse de ses fonctions d'autocorrélation (ACF) et d'autocorrélation partielle (PACF).

#II. Modélisation et analyse

Maintenant que la série a été rendue stationnaire, cette deuxième partie est consacrée à la modélisation de sa dynamique temporelle. L'objectif est d'identifier, d'ajuster et de valider le modèle de type AR ou ARMA le plus pertinent pour décrire la structure de dépendance des données.
```{r, echo=FALSE}
par(mfrow = c(2,1))

acf(des_data, lag.max = 36, xaxt = "n", main = "ACF")
axis(1, at = 0:36/12, labels = 0:36)
pacf(des_data, lag.max = 36, xaxt = "n", main = "PACF")
axis(1, at = 0:36/12, labels = 0:36)
```
L'analyse des corrélogrammes ACF et PACF révèle une structure de dépendance temporelle marquée par une forte saisonnalité. La fonction d'autocorrélation (ACF) présente un pic significatif au retard 12, avant de "couper" tandis que la fonction d'autocorrélation partielle (PACF) affiche un pic négatif particulièrement important à -0.5 pour le retard 12, et des pics au lag 24 et 36 sont moins proéminent, semble amorcer une décroissance lente et significative. Ce comportement, où l'autocorrélation parcielle saisonnière ne s'annule pas nettement mais diminue progressivement, suggère que le modèle pourrait bénéficier de l'ajout d'une composante de moyenne mobile saisonnière (SMA). Un modèle SARIMA, intégrant à la fois des termes SAR et SMA, pourrait donc être plus pertinent pour capturer l'ensemble de la dynamique saisonnière de la série.




Deux tests statistiques ont été appliqués à la série désaisonnalisée :
Test ADF (Augmented Dickey-Fuller) :


Statistique = -6.02


p-value = 0.01
 → On rejette l’hypothèse de non-stationnarité, la série est donc stationnaire.


Test KPSS (Kwiatkowski-Phillips-Schmidt-Shin) :


Statistique = 0.0148


p-value = 0.1
 → On ne rejette pas l’hypothèse de stationnarité.
Les deux tests aboutissent à la même conclusion : la série des_data est stationnaire après différenciation annuelle.
Cela confirme que la tendance et la saisonnalité ont été correctement supprimées, et que la série est maintenant prête pour la modélisation ARIMA.
```{r}


resultats <- data.frame(type = character(),
                       odre = integer(),
                       AIC = numeric(),
                       BIC = numeric())

for (p in 1:5){
  fit <- tryCatch({
    arima(des_data, order = c(p,0,0), method="ML")
  }, error=function(e) NULL)
  
  if(!is.null(fit)){
    resultats <- rbind(resultats, data.frame(
      type = "AR",
      ordre = p,
      AIC = AIC(fit),
      BIC = BIC(fit)
    ))
  }
}

for (q in 1:5){
  fit <- tryCatch({
    arima(des_data, order = c(0,0,q), method="ML")
  }, error=function(e) NULL)
  
  if(!is.null(fit)){
    resultats <- rbind(resultats, data.frame(
      type = "MA",
      ordre = q,
      AIC = AIC(fit),
      BIC = BIC(fit)
    ))
  }
}


meilleur_AIC <- resultats[which.min(resultats$AIC),]
meilleur_BIC <- resultats[which.min(resultats$BIC),]

meilleur_AIC_AR <- resultats[resultats$type == "AR", ][which.min(resultats[resultats$type == "AR", ]$AIC), ]
meilleur_BIC_AR <- resultats[resultats$type == "AR", ][which.min(resultats[resultats$type == "AR", ]$BIC), ]

meilleur_AIC_MA <- resultats[resultats$type == "MA", ][which.min(resultats[resultats$type == "MA", ]$AIC), ]
meilleur_BIC_MA <- resultats[resultats$type == "MA", ][which.min(resultats[resultats$type == "MA", ]$BIC), ]

cat("Meilleur modèle selon AIC:", meilleur_AIC$type, "(",meilleur_AIC$ordre, ")\n",
    "Meilleur modèle selon BIC:", meilleur_BIC$type, "(",meilleur_BIC$ordre, ")\n", 
    "Meilleur modèle AR selon AIC:", meilleur_AIC_AR$type, "(",meilleur_AIC_AR$ordre, ")\n",
    "Meilleur modèle AR selon BIC:", meilleur_BIC_AR$type, "(",meilleur_BIC_AR$ordre, ")\n",
    "Meilleur modèle MA selon AIC:", meilleur_AIC_MA$type, "(",meilleur_AIC_MA$ordre, ")\n",
    "Meilleur modèle MA selon BIC:", meilleur_BIC_MA$type, "(",meilleur_BIC_MA$ordre, ")\n"
    )

```
Effectivement, les modèles avec plus de paramètres ont un meilleur AIC mais c'est dû à un "sur-apprentissage" qui est mis en évidence par la mesure du BIC qui met les modèles AR(1) et MA(1) en avant. On comprend bien intuitivement que la température moyenne pour le mois de juin par exemple dépend peu de la température de la même année en Janvier. 

```{r, warning=FALSE}

resultats_ARMA <- data.frame(
  p = integer(),
  q = integer(),
  AIC = numeric(),
  BIC = numeric()
)

for (p in 0:5){
  for (q in 0:5){
    if (p==0 & q==0) next
    
    fit <- tryCatch({
      arima(des_data, order = c(p,0,q), method="ML")
    }, error = function(e) NULL)
    
    if (!is.null(fit)){
      resultats_ARMA <- rbind(resultats_ARMA, data.frame(
        p = p,
        q = q,
        AIC = AIC(fit),
        BIC = BIC(fit)
      ))
    }
  }
}


meilleur_AIC_ARMA <- resultats_ARMA[which.min(resultats_ARMA$AIC),]
meilleur_BIC_ARMA <- resultats_ARMA[which.min(resultats_ARMA$BIC),]

cat("\nMeilleur modèle ARMA selon AIC: ARMA(",meilleur_AIC_ARMA$p, "0",meilleur_AIC_ARMA$q, ")\n","Meilleur modèle ARMA selon BIC: ARMA(",meilleur_BIC_ARMA$p, "0",meilleur_BIC_ARMA$q, ")") 

resultats_ARMA$p <- as.factor(resultats_ARMA$p)
resultats_ARMA$q <- as.factor(resultats_ARMA$q)

heatmap_plot <- ggplot(resultats_ARMA, aes(x = q, y = p, fill = BIC)) +
  geom_tile(color = "white", lwd = 0.5) + 
  geom_text(aes(label = round(BIC, 1)), color = "black", size = 3.5) +
  scale_fill_viridis_c(direction = -1) + 
  labs(
    title = "Heatmap du BIC pour différents modèles ARMA(p,q)",
    x = "Ordre 'q' (Moyenne Mobile)",
    y = "Ordre 'p' (Autorégressif)",
    fill = "BIC"
  ) +
  theme_minimal() + 
  theme(
    plot.title = element_text(hjust = 0.5, size = 16),
    axis.title = element_text(size = 12)
  )


```
Analyse des résidus :
Pour le modèle AR(4) :


L’ACF des résidus montre encore des pics significatifs → autocorrélations résiduelles non négligeables.


Le test de Ljung–Box (p-value < 0.001) confirme la présence d’autocorrélation → modèle insuffisant.


Pour le modèle ARMA(5,5) :


L’ACF des résidus est plus aléatoire, avec des valeurs globalement dans les bandes de confiance.


Le test de Ljung–Box (p-value = 6.38×10⁻¹³) reste significatif, mais indique une amélioration par rapport au modèle AR pur.


L’histogramme des résidus est centré sur 0, proche d’une distribution normale.

Conclusion :
 Le modèle ARMA(5,5) améliore nettement l’ajustement par rapport au modèle AR(4), mais c’est le modèle saisonnier ARMA(12,12) restreint qui fournit les résidus les plus satisfaisants (non autocorrélés et à moyenne nulle).
 Il constitue donc le meilleur modèle pour la série désaisonnalisée.
```{r}
# Afficher le graphique
print(heatmap_plot)

```

Malgré le fait que le BIC pénalise plus un grand nombre d'estimateur, pour la mesure de performance du modèle, on a quand même un meilleur BIC pour le modèle ARMA(5,5), comme on le voit sur le graphe de HeatMap du BIC en fonction des paramètres p et q.


Le test est validé pour ce modèle. 

Dans une première approche de modélisation, nous nous tournons vers les structures les plus parcimonieuses : les modèles de moyenne mobile d'ordre 1, MA(1), et autorégressif d'ordre 1, AR(1). L'objectif est d'évaluer si une dépendance temporelle simple peut expliquer la dynamique de la série. 

```{r}
modele_AR_1 <- arima(des_data, order = c(1,0,0), method="ML")
modele_MA_1 <- arima(des_data, order = c(0,0,1), method="ML")
AIC_AR_1 = AIC(modele_AR_1)
AIC_MA_1 = AIC(modele_MA_1)

res_AR_1 <- residuals(modele_AR_1)
res_MA_1 <- residuals(modele_MA_1)
```

```{r}
par(mfrow = c(2,1))

acf(res_AR_1, lag.max = 36, xaxt = "n", main = "ACF des résidus AR(1)")
axis(1, at = 0:36/12, labels = 0:36)
acf(res_MA_1, lag.max = 36, xaxt = "n", main = "ACF des résidus MA(1)")
axis(1, at = 0:36/12, labels = 0:36)
```

```{r}
Box.test(res_AR_1, lag=12, type="Ljung-Box")
Box.test(res_MA_1, lag=12, type="Ljung-Box")
```
Cependant, l'analyse des résidus de ces deux modèles montre rapidement leurs limites : ils s'avèrent insuffisants pour capturer toute la structure de dépendance, laissant persister une autocorrélation significative qui invalide leur pertinence.

```{r}
modele_AR <- arima(des_data, order = c(4,0,0), method="ML")
modele_ARMA <- arima(des_data, order = c(5,0,5), method="ML")
AIC_ARMA = AIC(modele_ARMA)
AIC_AR = AIC(modele_AR)

res_AR <- residuals(modele_AR)
res_ARMA <- residuals(modele_ARMA)
```


```{r}
par(mfrow = c(2,1))

acf(res_AR, lag.max = 36, xaxt = "n", main = "ACF des résidus AR(4)")
axis(1, at = 0:36/12, labels = 0:36)
acf(res_ARMA, lag.max = 36, xaxt = "n", main = "ACF des résidus ARMA(5,0,5)")
axis(1, at = 0:36/12, labels = 0:36)
```
les deux corrélogrammes affichent un pic de corrélation négatif et statistiquement significatif au douzième retard (lag 12), avec des valeurs respectives de -0.4 et -0.5. Ce pic au lag 12 est un signal clair que les résidus ne se comportent pas comme un bruit blanc, mais conservent une information temporelle prédictible.
```{r}
Box.test(res_AR, lag=12, type="Ljung-Box")
Box.test(res_ARMA, lag=12, type="Ljung-Box")
```
L'application du test de Ljung-Box sur les séries de résidus est sans appel : elle retourne des p-valeurs numériquement nulles ("zéro machine"). Ce résultat apporte une preuve statistique irréfutable pour rejeter l'hypothèse nulle d'indépendance des résidus. Il est donc formellement démontré qu'ils ne peuvent être considérés comme un bruit blanc, ce que l'inspection visuelle de leur ACF laissait déjà fortement présager.

```{r}
hist(res_AR, main = "Histogramme des résidus AR(4)", xlab = "Résidus")
hist(res_ARMA, main = "Histogramme des résidus ARMA(5,0,5)", xlab = "Résidus")

```
De surcroît, l'histogramme des résidus s'écarte visiblement d'une distribution normale, violant ainsi une autre hypothèse centrale du modèle. Face à des résidus qui sont à la fois autocorrélés et non-normalement distribués, nous devons conclure que les modèles ajustés sont mal spécifiés et incapables de capturer la structure sous-jacente des données.


On passe à des modèles qui prennent en compte la saisonnalité dans les données (le mois de l'année précédente...)
les trois modèles suivants : AR(12) (subset{lags: 1, 12},, AR(36) (subset{lags: 1, 11, 12, 24, 36}, ARMA(12,0,12) (subset {AR:1,12 ; MA:12). 
```{r}
fixed_ar_36 <- c(NA, rep(0,10), NA, NA, rep(0,11),NA, rep(0,11), NA)  
modele_subsetAR_36 <- Arima(des_data, order=c(37,0,0), include.mean=FALSE, fixed=fixed_ar_36)
nb_param_AR_36<- coef(modele_subsetAR_36)


fixed_ar_12 <- c(NA, rep(0,10), NA)  # φ1 et φ12 libres
modele_subsetAR_12 <- Arima(des_data, order=c(12,0,0), include.mean=FALSE, fixed=fixed_ar_12)
nb_param_AR_12<- coef(modele_subsetAR_12)

fixed_arma <- c(NA, rep(0,10), NA,      # AR part : φ1 et φ12 libres
                rep(0,11), NA)          # MA part : θ12 libre
modele_subsetARMA <- Arima(des_data, order=c(12,0,12), include.mean=FALSE, fixed=fixed_arma)

res_subsetAR_12 <- residuals(modele_subsetAR_12)
res_subsetAR_36 <- residuals(modele_subsetAR_36)
res_subsetARMA <- residuals(modele_subsetARMA)

acf(res_subsetAR_12, lag.max = 36, xaxt = "n", main = "ACF des résidus AR(12) (subset{lags: 1, 12}")
axis(1, at = 0:36/12, labels = 0:36)
```
L'analyse de la fonction d'autocorrélation (ACF) des résidus du modèle AR(12) montre la persistance de pics significatifs aux retards saisonniers 12 et 24.
```{r}
acf(res_subsetAR_36, lag.max = 36, xaxt = "n", main = "ACF des résidus AR(36) (subset{lags: 1, 11, 12, 24, 36}")
axis(1, at = 0:36/12, labels = 0:36)
```
L'analyse de la fonction d'autocorrélation (ACF) des résidus du modèle AR(36) subset{1,11,12,24,36} montre la persistance de pics significatifs aux retards saisonniers 10, 13 et 24 et 26.

```{r}
acf(res_subsetARMA, lag.max = 36, xaxt = "n", main = "ACF des résidus ARMA(12,0,12) (subset {AR:1,12 ; MA:12)")
axis(1, at = 0:36/12, labels = 0:36)
```
L'analyse de la fonction d'autocorrélation (ACF) des résidus du modèle ARMA(12) subset {1,12; 12} montre la persistance d'un pic significatif au retard 12.



## Test de Ljung–Box

Pour valider formellement si les résidus de notre modèle se comportent comme un bruit blanc, nous utilisons le test de Ljung-Box. Ce test statistique permet de déterminer si un ensemble d'autocorrélations d'une série temporelle est globalement non nul.

L'hypothèse nulle (H0) du test est qu'il n'y a pas d'autocorrélation dans les résidus jusqu'au retard m. La statistique du test, notée Q, est calculée comme suit :

$$
Q = n (n + 2) \sum_{k=1}^{m} \frac{\hat{\rho}(k)^2}{n - k}
$$

où :

n est le nombre d'observations.

m est le nombre de retards (lags) testés.

ρ(k) est l'autocorrélation empirique des résidus au retard k.

Sous l'hypothèse nulle, la statistique Q suit une loi du Khi-deux. Un point crucial est l'ajustement de ses degrés de liberté : ils sont égaux à m−fitdf, où fitdf représente le nombre de paramètres estimés dans le modèle (par exemple, les coefficients AR et MA). Cet ajustement est nécessaire car l'estimation des paramètres du modèle contraint les résidus et réduit leur variabilité.

Pour un niveau de confiance de 95%, la règle de décision est la suivante : si la p-value calculée est inférieure à 0.05, nous rejetons l'hypothèse nulle et concluons que les résidus sont significativement autocorrélés. Si la p-value est supérieure à 0.05, nous ne pouvons pas rejeter H0 et nous considérons que les résidus sont bien indépendants.
```{r, echo=FALSE}
fixed_ar_36 <- c(NA, rep(0,10), NA, NA, rep(0,11),NA, rep(0,11), NA)  
modele_subsetAR_36 <- Arima(des_data, order=c(37,0,0), include.mean=FALSE, fixed=fixed_ar_36)

fixed_ar_12 <- c(NA, rep(0,10), NA)
modele_subsetAR_12 <- Arima(des_data, order=c(12,0,0), include.mean=FALSE, fixed=fixed_ar_12)


fixed_arma <- c(NA, rep(0,10), NA,      # AR part : φ1 et φ12 libres
                rep(0,11), NA)          # MA part : θ12 libre
modele_subsetARMA <- Arima(des_data, order=c(12,0,12), include.mean=FALSE, fixed=fixed_arma)
```


```{r, echo=FALSE}
# Calcul des résidus
res_subsetAR_12 <- residuals(modele_subsetAR_12)
res_subsetAR_36 <- residuals(modele_subsetAR_36)
res_subsetARMA <- residuals(modele_subsetARMA)
```


```{r, echo=FALSE}
# Tests de Ljung-Box
lb_AR12_lag12 <- Box.test(res_subsetAR_12, lag=12, type="Ljung-Box", fitdf = 2)
lb_AR12_lag24 <- Box.test(res_subsetAR_12, lag=24, type="Ljung-Box", fitdf = 2)

lb_AR36_lag12 <- Box.test(res_subsetAR_36, lag=12, type="Ljung-Box", fitdf = 5)
lb_AR36_lag24 <- Box.test(res_subsetAR_36, lag=24, type="Ljung-Box", fitdf = 5)
lb_AR36_lag36 <- Box.test(res_subsetAR_36, lag=36, type="Ljung-Box", fitdf = 5)

lb_ARMA_lag12 <- Box.test(res_subsetARMA, lag=12, type="Ljung-Box", fitdf = 3)
lb_ARMA_lag24 <- Box.test(res_subsetARMA, lag=24, type="Ljung-Box", fitdf = 3)

```


```{r, echo=FALSE}
# Graphiques des lois du Chi² séparés par ddl
par(mfrow = c(3,2), mar = c(4, 4, 3, 2))

x <- seq(0, 50, length.out = 500)

# 1. Chi² avec ddl = 10 (AR12, lag=12)
plot(x, dchisq(x, df = 10), type = "l", lwd = 2, col = "blue",
     main = expression(paste(chi^2, "(ddl=10) - AR(12) lag=12")),
     ylab = "Densité", xlab = "x")
abline(v = lb_AR12_lag12$statistic, col = "red", lty = 2, lwd = 2)
legend("topright", 
       legend = c("χ²(10)", 
                  paste0("Q observé = ", round(lb_AR12_lag12$statistic, 2)),
                  paste0("p-value = ", round(lb_AR12_lag12$p.value, 4))),
       col = c("blue", "red", NA), lwd = c(2, 2, NA), lty = c(1, 2, NA),
       cex = 0.8, bty = "n")

# 2. Chi² avec ddl = 22 (AR12, lag=24)
plot(x, dchisq(x, df = 22), type = "l", lwd = 2, col = "blue",
     main = expression(paste(chi^2, "(ddl=22) - AR(12) lag=24")),
     ylab = "Densité", xlab = "x")
abline(v = lb_AR12_lag24$statistic, col = "red", lty = 2, lwd = 2)
legend("topright", 
       legend = c("χ²(22)", 
                  paste0("Q observé = ", round(lb_AR12_lag24$statistic, 2)),
                  paste0("p-value = ", round(lb_AR12_lag24$p.value, 4))),
       col = c("blue", "red", NA), lwd = c(2, 2, NA), lty = c(1, 2, NA),
       cex = 0.8, bty = "n")

# 3. Chi² avec ddl = 7 (AR36, lag=12)
plot(x, dchisq(x, df = 7), type = "l", lwd = 2, col = "darkgreen",
     main = expression(paste(chi^2, "(ddl=7) - AR(37) lag=12")),
     ylab = "Densité", xlab = "x")
abline(v = lb_AR36_lag12$statistic, col = "red", lty = 2, lwd = 2)
legend("topright", 
       legend = c("χ²(7)", 
                  paste0("Q observé = ", round(lb_AR36_lag12$statistic, 2)),
                  paste0("p-value = ", round(lb_AR36_lag12$p.value, 4))),
       col = c("darkgreen", "red", NA), lwd = c(2, 2, NA), lty = c(1, 2, NA),
       cex = 0.8, bty = "n")

# 4. Chi² avec ddl = 19 (AR36, lag=24)
plot(x, dchisq(x, df = 19), type = "l", lwd = 2, col = "darkgreen",
     main = expression(paste(chi^2, "(ddl=19) - AR(37) lag=24")),
     ylab = "Densité", xlab = "x")
abline(v = lb_AR36_lag24$statistic, col = "red", lty = 2, lwd = 2)
legend("topright", 
       legend = c("χ²(19)", 
                  paste0("Q observé = ", round(lb_AR36_lag24$statistic, 2)),
                  paste0("p-value = ", round(lb_AR36_lag24$p.value, 4))),
       col = c("darkgreen", "red", NA), lwd = c(2, 2, NA), lty = c(1, 2, NA),
       cex = 0.8, bty = "n")

# 5. Chi² avec ddl = 31 (AR36, lag=36)
plot(x, dchisq(x, df = 31), type = "l", lwd = 2, col = "darkgreen",
     main = expression(paste(chi^2, "(ddl=31) - AR(37) lag=36")),
     ylab = "Densité", xlab = "x")
abline(v = lb_AR36_lag36$statistic, col = "red", lty = 2, lwd = 2)
legend("topright", 
       legend = c("χ²(31)", 
                  paste0("Q observé = ", round(lb_AR36_lag36$statistic, 2)),
                  paste0("p-value = ", round(lb_AR36_lag36$p.value, 4))),
       col = c("darkgreen", "red", NA), lwd = c(2, 2, NA), lty = c(1, 2, NA),
       cex = 0.8, bty = "n")

# 6. Chi² avec ddl = 9 (ARMA, lag=12)
plot(x, dchisq(x, df = 9), type = "l", lwd = 2, col = "purple",
     main = expression(paste(chi^2, "(ddl=9) - ARMA lag=12")),
     ylab = "Densité", xlab = "x")
abline(v = lb_ARMA_lag12$statistic, col = "red", lty = 2, lwd = 2)
legend("topright", 
       legend = c("χ²(9)", 
                  paste0("Q observé = ", round(lb_ARMA_lag12$statistic, 2)),
                  paste0("p-value = ", round(lb_ARMA_lag12$p.value, 4))),
       col = c("purple", "red", NA), lwd = c(2, 2, NA), lty = c(1, 2, NA),
       cex = 0.8, bty = "n")
```
Parmi l'ensemble des modèles évalués, seul le modèle ARMA(12){1,12; 12} satisfait aux critères du test de Ljung-Box qu'il y ait eu fitdf rajouté en dans le test de Box Ljung ou non, indiquant une absence d'autocorrélation significative dans ses résidus.

```{r, echo=FALSE}
# Graphique pour ARMA lag=24
par(mfrow = c(1,1), mar = c(4, 4, 3, 2))
plot(x, dchisq(x, df = 21), type = "l", lwd = 2, col = "purple",
     main = expression(paste(chi^2, "(ddl=21) - ARMA lag=24")),
     ylab = "Densité", xlab = "x")
abline(v = lb_ARMA_lag24$statistic, col = "red", lty = 2, lwd = 2)
legend("topright", 
       legend = c("χ²(21)", 
                  paste0("Q observé = ", round(lb_ARMA_lag24$statistic, 2)),
                  paste0("p-value = ", round(lb_ARMA_lag24$p.value, 4))),
       col = c("purple", "red", NA), lwd = c(2, 2, NA), lty = c(1, 2, NA),
       cex = 0.8, bty = "n")
```


